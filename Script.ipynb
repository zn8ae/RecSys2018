{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import codecs\n",
    "import datetime\n",
    "\n",
    "\n",
    "pretty = True\n",
    "compact = False\n",
    "cache = {}\n",
    "\n",
    "def get_playlist(pid):\n",
    "    if pid >=0 and pid < 1000000:\n",
    "        low = 1000 * int(pid / 1000)\n",
    "        high = low + 999\n",
    "        offset = pid - low\n",
    "        path = \"./mpd.v1/data/mpd.slice.\" + str(low) + '-' + str(high) + \".json\"\n",
    "        if not path in cache:\n",
    "            f = codecs.open(path, 'r', 'utf-8')\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            playlist = json.loads(js)\n",
    "            cache[path] = playlist\n",
    "\n",
    "        playlist = cache[path]['playlists'][offset]\n",
    "        return playlist\n",
    "\n",
    "def get_playlists_in_range(start, end):\n",
    "    pls = []\n",
    "    try:\n",
    "        istart = int(start)\n",
    "        iend = int(end)\n",
    "        if istart <= iend and istart >= 0 and iend <= 1000000:\n",
    "            for pid in xrange(istart, iend):\n",
    "                pls.append(get_playlist(pid))\n",
    "    except:\n",
    "        raise\n",
    "        print \"bad pid\"\n",
    "    return pls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_playlists = 0\n",
    "total_tracks = 0\n",
    "tracks = set()\n",
    "artists = set()\n",
    "albums = set()\n",
    "titles = set()\n",
    "total_descriptions = 0\n",
    "ntitles = set()\n",
    "\n",
    "playlist_length_histogram = collections.Counter()\n",
    "num_followers_histogram = collections.Counter()\n",
    "artist_histogram = collections.Counter()\n",
    "track_histogram = collections.Counter()\n",
    "\n",
    "\n",
    "def process_playlist(playlist):\n",
    "    global total_playlists, total_tracks, total_descriptions\n",
    "\n",
    "    total_playlists += 1\n",
    "    # print playlist['playlist_id'], playlist['name']\n",
    "\n",
    "    if 'description' in playlist:\n",
    "        total_descriptions += 1\n",
    "\n",
    "    titles.add(playlist['name'])\n",
    "    nname = normalize_name(playlist['name'])\n",
    "    ntitles.add(nname)\n",
    "\n",
    "    playlist_length_histogram[playlist['num_tracks']] += 1\n",
    "    num_followers_histogram[playlist['num_followers']] += 1\n",
    "\n",
    "    for track in playlist['tracks']:\n",
    "        total_tracks += 1\n",
    "        albums.add(track['album_uri'])\n",
    "        tracks.add(track['track_uri'])\n",
    "        artists.add(track['artist_uri'])\n",
    "\n",
    "        full_name = track['track_name'] + \" by \" + track['artist_name']\n",
    "        artist_histogram[track['artist_name']] += 1\n",
    "        track_histogram[full_name] += 1\n",
    "\n",
    "def normalize_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[.,\\/#!$%\\^\\*;:{}=\\_`~()@]\", ' ', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary():\n",
    "    print\n",
    "    print \"number of playlists\", total_playlists\n",
    "    print \"number of tracks\", total_tracks\n",
    "    print \"number of unique tracks\", len(tracks)\n",
    "    print \"number of unique albums\", len(albums)\n",
    "    print \"number of unique artists\", len(artists)\n",
    "    print \"number of unique titles\", len(titles)\n",
    "    print \"number of playlists with descriptions\", total_descriptions\n",
    "    print \"number of unique normalized titles\", len(ntitles)\n",
    "    print \"avg playlist length\", float(total_tracks) / total_playlists\n",
    "    \n",
    "    print\n",
    "    print \"top tracks\"\n",
    "    for track, count in track_histogram.most_common(20):\n",
    "        print \"%7d %s\" % (count, track)\n",
    "\n",
    "    print\n",
    "    print \"top artists\"\n",
    "    for artist, count in artist_histogram.most_common(20):\n",
    "        print \"%7d %s\" % (count, artist)\n",
    "\n",
    "    print\n",
    "    print \"playlist length histogram\"\n",
    "    for length, count in playlist_length_histogram.most_common(20):\n",
    "        print \"%7d %d\" % (count, length)\n",
    "\n",
    "    print\n",
    "    print \"num followers histogram\"\n",
    "    for followers, count in num_followers_histogram.most_common(20):\n",
    "        print \"%7d %d\" % (count, followers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_track = {}\n",
    "def process_tracks(playlist):\n",
    "    global uri_track\n",
    "    document = []\n",
    "    \n",
    "    for track in playlist['tracks']:\n",
    "        uri = track['track_uri'].split(':')[2]\n",
    "        document.append(uri)\n",
    "        uri_track[uri] = track\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "l = get_playlists_in_range(0, 10000)\n",
    "l = np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "l_train, l_test = train_test_split(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "#recommend for one list\n",
    "#go through training set, calculate score, stored in list\n",
    "#return top n ranked list sorted by score\n",
    "def calc_score(playlist):\n",
    "    dic = {}\n",
    "    tracks = playlist['tracks']\n",
    "    nname_test = []\n",
    "    for track in tracks:\n",
    "        nname = normalize_name(track['track_name'])\n",
    "        nname_test.append(nname)\n",
    "    total = len(nname_test)\n",
    "    \n",
    "    #for each playlist in training set, calculate score and add in result\n",
    "    for pl in l_train:\n",
    "        count = 0\n",
    "        tracks = pl['tracks']\n",
    "        for track in tracks:\n",
    "            nname = normalize_name(track['track_name'])\n",
    "            if nname in nname_test:\n",
    "                count+=1\n",
    "        #after finishing counting\n",
    "        dic[pl['pid']] = float(count)/total\n",
    "        \n",
    "    return dic, nname_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "dic, names = calc_score(l_test[0])\n",
    "result = sorted(dic.items(), key=operator.itemgetter(1))\n",
    "result.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = get_pid_tracks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(pt, scores, names, count):\n",
    "    result = []\n",
    "    for score in scores:\n",
    "        pid = score[0]\n",
    "        tracks = pt[pid]\n",
    "        for track in tracks:\n",
    "            nname = normalize_name(track['track_name'])\n",
    "            if nname not in names:\n",
    "                result.append(track)\n",
    "                if len(result) >= count:\n",
    "                    return result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = recommend(pt, result, names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pl in l_test:\n",
    "    dic, names = calc_score(pl)\n",
    "    result = sorted(dic.items(), key=operator.itemgetter(1))\n",
    "    result.reverse()\n",
    "    print (recommend(pt, result, names, 5))\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "- uri_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for plist in l_train:\n",
    "    documents.append(process_tracks(plist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-25 14:19:24,825 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-04-25 14:19:24,827 : INFO : collecting all words and their counts\n",
      "2018-04-25 14:19:24,828 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-04-25 14:19:25,035 : INFO : collected 140941 word types from a corpus of 500151 raw words and 7500 sentences\n",
      "2018-04-25 14:19:25,036 : INFO : Loading a fresh vocabulary\n",
      "2018-04-25 14:19:25,354 : INFO : min_count=2 retains 50077 unique words (35% of original 140941, drops 90864)\n",
      "2018-04-25 14:19:25,355 : INFO : min_count=2 leaves 409287 word corpus (81% of original 500151, drops 90864)\n",
      "2018-04-25 14:19:25,508 : INFO : deleting the raw counts dictionary of 140941 items\n",
      "2018-04-25 14:19:25,512 : INFO : sample=0.001 downsamples 0 most-common words\n",
      "2018-04-25 14:19:25,513 : INFO : downsampling leaves estimated 409287 word corpus (100.0% of prior 409287)\n",
      "2018-04-25 14:19:25,664 : INFO : estimated required memory for 50077 words and 150 dimensions: 85130900 bytes\n",
      "2018-04-25 14:19:25,665 : INFO : resetting layer weights\n",
      "2018-04-25 14:19:26,171 : INFO : training model with 10 workers on 50077 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-04-25 14:19:26,628 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:26,636 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:26,643 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:26,649 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:26,660 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:26,665 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:26,667 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:26,682 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:26,683 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:26,684 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:26,685 : INFO : EPOCH - 1 : training on 500151 raw words (409287 effective words) took 0.5s, 803179 effective words/s\n",
      "2018-04-25 14:19:27,152 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:27,157 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:27,158 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:27,160 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:27,161 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:27,165 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:27,179 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:27,181 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:27,182 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:27,188 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:27,189 : INFO : EPOCH - 2 : training on 500151 raw words (409287 effective words) took 0.5s, 824197 effective words/s\n",
      "2018-04-25 14:19:27,619 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:27,635 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:27,640 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:27,645 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:27,646 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:27,648 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:27,650 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:27,652 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:27,654 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:27,669 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:27,670 : INFO : EPOCH - 3 : training on 500151 raw words (409287 effective words) took 0.5s, 861735 effective words/s\n",
      "2018-04-25 14:19:28,050 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:28,076 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:28,079 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:28,080 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:28,081 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:28,085 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:28,087 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:28,089 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:28,105 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:28,106 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:28,107 : INFO : EPOCH - 4 : training on 500151 raw words (409287 effective words) took 0.4s, 965079 effective words/s\n",
      "2018-04-25 14:19:28,493 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:28,515 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:28,516 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:28,517 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:28,519 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:28,520 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:28,522 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:28,523 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:28,537 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:28,539 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:28,540 : INFO : EPOCH - 5 : training on 500151 raw words (409287 effective words) took 0.4s, 955711 effective words/s\n",
      "2018-04-25 14:19:28,542 : INFO : training on a 2500755 raw words (2046435 effective words) took 2.4s, 863454 effective words/s\n",
      "2018-04-25 14:19:28,544 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-04-25 14:19:28,546 : INFO : training model with 10 workers on 50077 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-04-25 14:19:28,948 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:28,953 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:28,954 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:28,956 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:28,957 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:28,962 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:28,974 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:28,976 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:28,979 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:28,982 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:28,984 : INFO : EPOCH - 1 : training on 500151 raw words (409287 effective words) took 0.4s, 947597 effective words/s\n",
      "2018-04-25 14:19:29,373 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:29,387 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:29,388 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:29,390 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-25 14:19:29,395 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:29,397 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:29,398 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:29,400 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:29,409 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:29,413 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:29,415 : INFO : EPOCH - 2 : training on 500151 raw words (409287 effective words) took 0.4s, 960544 effective words/s\n",
      "2018-04-25 14:19:29,782 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:29,802 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:29,822 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:29,824 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:29,825 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:29,826 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:29,827 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:29,830 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:29,846 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:29,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:29,849 : INFO : EPOCH - 3 : training on 500151 raw words (409287 effective words) took 0.4s, 957560 effective words/s\n",
      "2018-04-25 14:19:30,231 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:30,262 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:30,265 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:30,276 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:30,279 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:30,281 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:30,282 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:30,283 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:30,285 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:30,294 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:30,295 : INFO : EPOCH - 4 : training on 500151 raw words (409287 effective words) took 0.4s, 930447 effective words/s\n",
      "2018-04-25 14:19:30,700 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:30,707 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:30,709 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:30,710 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:30,711 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:30,716 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:30,727 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:30,729 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:30,732 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:30,734 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:30,735 : INFO : EPOCH - 5 : training on 500151 raw words (409287 effective words) took 0.4s, 940729 effective words/s\n",
      "2018-04-25 14:19:31,144 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:31,150 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:31,151 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:31,153 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:31,158 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:31,159 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:31,161 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:31,162 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:31,173 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:31,176 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:31,177 : INFO : EPOCH - 6 : training on 500151 raw words (409287 effective words) took 0.4s, 939827 effective words/s\n",
      "2018-04-25 14:19:31,556 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:31,596 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:31,600 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:31,601 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:31,602 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:31,604 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:31,605 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:31,626 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:31,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:31,630 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:31,631 : INFO : EPOCH - 7 : training on 500151 raw words (409287 effective words) took 0.4s, 910891 effective words/s\n",
      "2018-04-25 14:19:32,028 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:32,037 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:32,045 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:32,055 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:32,057 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:32,070 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:32,072 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:32,074 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:32,075 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:32,076 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:32,077 : INFO : EPOCH - 8 : training on 500151 raw words (409287 effective words) took 0.4s, 943747 effective words/s\n",
      "2018-04-25 14:19:32,455 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:32,493 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:32,500 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-25 14:19:32,501 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:32,506 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:32,509 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:32,510 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:32,512 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:32,523 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:32,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:32,527 : INFO : EPOCH - 9 : training on 500151 raw words (409287 effective words) took 0.4s, 920700 effective words/s\n",
      "2018-04-25 14:19:32,918 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-25 14:19:32,921 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-25 14:19:32,940 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-25 14:19:32,950 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-25 14:19:32,951 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-25 14:19:32,953 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-25 14:19:32,954 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-25 14:19:32,956 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-25 14:19:32,957 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-25 14:19:32,972 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-25 14:19:32,973 : INFO : EPOCH - 10 : training on 500151 raw words (409287 effective words) took 0.4s, 942163 effective words/s\n",
      "2018-04-25 14:19:32,976 : INFO : training on a 5001510 raw words (4092870 effective words) took 4.4s, 924176 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4092870, 5001510)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'26rdOwwjC2UnweK3xeS58u'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_train[0]['tracks'][0]['track_uri'].split(\":\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'album_name': u'MY HOUSE',\n",
       " u'album_uri': u'spotify:album:5lkNnHVlnCCCV304t89wOH',\n",
       " u'artist_name': u'Flo Rida',\n",
       " u'artist_uri': u'spotify:artist:0jnsk9HBra6NMjO2oANoPY',\n",
       " u'duration_ms': 190185,\n",
       " u'pos': 0,\n",
       " u'track_name': u'GDFR (feat. Sage The Gemini & Lookas)',\n",
       " u'track_uri': u'spotify:track:26rdOwwjC2UnweK3xeS58u'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_train[0]['tracks'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = l_train[0]['tracks'][0]['track_uri'].split(\":\")[2]\n",
    "rec_list = model.wv.most_similar(positive=w1, topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: GDFR (feat. Sage The Gemini & Lookas) By Flo Rida\n",
      "\n",
      "Shutterbugg By Big Boi\n",
      "similarity: 0.984748542309\n",
      "\n",
      "Watch Me (Whip / Nae Nae) By Silentó\n",
      "similarity: 0.979164481163\n",
      "\n",
      "Tribe (feat. Jesse Boykins III) By Theophilus London\n",
      "similarity: 0.976357161999\n",
      "\n",
      "Drunk in Love By Beyoncé\n",
      "similarity: 0.974434196949\n",
      "\n",
      "I Don't Mind By Usher\n",
      "similarity: 0.974072992802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Test: \" + uri_track[w1]['track_name'] + \" By \" + uri_track[w1]['artist_name']\n",
    "print\n",
    "for l in rec_list:\n",
    "    print uri_track[l[0]]['track_name'] + \" By \" + uri_track[l[0]]['artist_name']\n",
    "    print \"similarity: \" + str(l[1])\n",
    "    print\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "- R-precision is the number of retrieved relevant tracks divided by the number of known relevant tracks (i.e., the number of withheld tracks):\n",
    "- Jaccard Similarity measures intersection over union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89787\n"
     ]
    }
   ],
   "source": [
    "len(l_test)\n",
    "scores=[]\n",
    "count = 0\n",
    "for plist in l_test:\n",
    "    tracks = plist['tracks']\n",
    "    #withheld tracks\n",
    "    t_train, t_test = train_test_split(tracks)\n",
    "    #predict\n",
    "    predicts = []\n",
    "    for t in t_train:\n",
    "        uri = t['track_uri'].split(\":\")[-1]\n",
    "        if uri not in model.wv.vocab.keys():\n",
    "            continue\n",
    "        res = model.wv.most_similar(positive=uri)\n",
    "        count+=1\n",
    "    #calculate Jaccard Sim & R-precision\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
